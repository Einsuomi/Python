{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>claps</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Justin Lee</td>\n",
       "      <td>8.3K</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/swlh/chatbots-were-the-next...</td>\n",
       "      <td>Chatbots were the next big thing: what happene...</td>\n",
       "      <td>Oh, how the headlines blared:\\nChatbots were T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Conor Dewey</td>\n",
       "      <td>1.4K</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/python-for-data...</td>\n",
       "      <td>Python for Data Science: 8 Concepts You May Ha...</td>\n",
       "      <td>If you’ve ever found yourself looking up the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>William Koehrsen</td>\n",
       "      <td>2.8K</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/automated-featu...</td>\n",
       "      <td>Automated Feature Engineering in Python – Towa...</td>\n",
       "      <td>Machine learning is increasingly moving from h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gant Laborde</td>\n",
       "      <td>1.3K</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.freecodecamp.org/machine-learni...</td>\n",
       "      <td>Machine Learning: how to go from Zero to Hero ...</td>\n",
       "      <td>If your understanding of A.I. and Machine Lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emmanuel Ameisen</td>\n",
       "      <td>935</td>\n",
       "      <td>11</td>\n",
       "      <td>https://blog.insightdatascience.com/reinforcem...</td>\n",
       "      <td>Reinforcement Learning from scratch – Insight ...</td>\n",
       "      <td>Want to learn about applied Artificial Intelli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>Daniel Simmons</td>\n",
       "      <td>3.4K</td>\n",
       "      <td>8</td>\n",
       "      <td>https://itnext.io/you-can-build-a-neural-netwo...</td>\n",
       "      <td>You can build a neural network in JavaScript e...</td>\n",
       "      <td>Click here to share this article on LinkedIn »...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>Eugenio Culurciello</td>\n",
       "      <td>2.8K</td>\n",
       "      <td>13</td>\n",
       "      <td>https://towardsdatascience.com/artificial-inte...</td>\n",
       "      <td>Artificial Intelligence, AI in 2018 and beyond...</td>\n",
       "      <td>These are my opinions on where deep neural net...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>Devin Soni</td>\n",
       "      <td>5.8K</td>\n",
       "      <td>4</td>\n",
       "      <td>https://towardsdatascience.com/spiking-neural-...</td>\n",
       "      <td>Spiking Neural Networks, the Next Generation o...</td>\n",
       "      <td>Everyone who has been remotely tuned in to rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>Carlos E. Perez</td>\n",
       "      <td>3.9K</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/intuitionmachine/neurons-ar...</td>\n",
       "      <td>Surprise! Neurons are Now More Complex than We...</td>\n",
       "      <td>One of the biggest misconceptions around is th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>Nityesh Agarwal</td>\n",
       "      <td>2.4K</td>\n",
       "      <td>13</td>\n",
       "      <td>https://towardsdatascience.com/wth-does-a-neur...</td>\n",
       "      <td>“WTH does a neural network even learn??” — a n...</td>\n",
       "      <td>I believe, we all have that psychologist/philo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>337 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  author claps  reading_time  \\\n",
       "0             Justin Lee  8.3K            11   \n",
       "1            Conor Dewey  1.4K             7   \n",
       "2       William Koehrsen  2.8K            11   \n",
       "3           Gant Laborde  1.3K             7   \n",
       "4       Emmanuel Ameisen   935            11   \n",
       "..                   ...   ...           ...   \n",
       "332       Daniel Simmons  3.4K             8   \n",
       "333  Eugenio Culurciello  2.8K            13   \n",
       "334           Devin Soni  5.8K             4   \n",
       "335      Carlos E. Perez  3.9K             7   \n",
       "336      Nityesh Agarwal  2.4K            13   \n",
       "\n",
       "                                                  link  \\\n",
       "0    https://medium.com/swlh/chatbots-were-the-next...   \n",
       "1    https://towardsdatascience.com/python-for-data...   \n",
       "2    https://towardsdatascience.com/automated-featu...   \n",
       "3    https://medium.freecodecamp.org/machine-learni...   \n",
       "4    https://blog.insightdatascience.com/reinforcem...   \n",
       "..                                                 ...   \n",
       "332  https://itnext.io/you-can-build-a-neural-netwo...   \n",
       "333  https://towardsdatascience.com/artificial-inte...   \n",
       "334  https://towardsdatascience.com/spiking-neural-...   \n",
       "335  https://medium.com/intuitionmachine/neurons-ar...   \n",
       "336  https://towardsdatascience.com/wth-does-a-neur...   \n",
       "\n",
       "                                                 title  \\\n",
       "0    Chatbots were the next big thing: what happene...   \n",
       "1    Python for Data Science: 8 Concepts You May Ha...   \n",
       "2    Automated Feature Engineering in Python – Towa...   \n",
       "3    Machine Learning: how to go from Zero to Hero ...   \n",
       "4    Reinforcement Learning from scratch – Insight ...   \n",
       "..                                                 ...   \n",
       "332  You can build a neural network in JavaScript e...   \n",
       "333  Artificial Intelligence, AI in 2018 and beyond...   \n",
       "334  Spiking Neural Networks, the Next Generation o...   \n",
       "335  Surprise! Neurons are Now More Complex than We...   \n",
       "336  “WTH does a neural network even learn??” — a n...   \n",
       "\n",
       "                                                  text  \n",
       "0    Oh, how the headlines blared:\\nChatbots were T...  \n",
       "1    If you’ve ever found yourself looking up the s...  \n",
       "2    Machine learning is increasingly moving from h...  \n",
       "3    If your understanding of A.I. and Machine Lear...  \n",
       "4    Want to learn about applied Artificial Intelli...  \n",
       "..                                                 ...  \n",
       "332  Click here to share this article on LinkedIn »...  \n",
       "333  These are my opinions on where deep neural net...  \n",
       "334  Everyone who has been remotely tuned in to rec...  \n",
       "335  One of the biggest misconceptions around is th...  \n",
       "336  I believe, we all have that psychologist/philo...  \n",
       "\n",
       "[337 rows x 6 columns]"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles=pd.read_csv(\"Medium_articles.csv\")\n",
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 337 entries, 0 to 336\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   author        337 non-null    object\n",
      " 1   claps         337 non-null    object\n",
      " 2   reading_time  337 non-null    int64 \n",
      " 3   link          337 non-null    object\n",
      " 4   title         337 non-null    object\n",
      " 5   text          337 non-null    object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 15.9+ KB\n"
     ]
    }
   ],
   "source": [
    "articles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if you’ve ever found yourself looking up the same question, concept, or syntax over and over again when programming, you’re not alone.\n",
      "i find myself doing this constantly.\n",
      "while it’s not unnatural to look things up on stackoverflow or other resources, it does slow you down a good bit and raise questions as to your complete understanding of the language.\n",
      "we live in a world where there is a seemingly infinite amount of accessible, free resources looming just one search away at all times. however, this can be both a blessing and a curse. when not managed effectively, an over-reliance on these resources can build poor habits that will set you back long-term.\n",
      "personally, i find myself pulling code from similar discussion threads several times, rather than taking the time to learn and solidify the concept so that i can reproduce the code myself the next time.\n",
      "this approach is lazy and while it may be the path of least resistance in the short-term, it will ultimately hurt your growth, productivity, and ability to recall syntax (cough, interviews) down the line.\n",
      "recently, i’ve been working through an online data science course titled python for data science and machine learning on udemy (oh god, i sound like that guy on youtube). over the early lectures in the series, i was reminded of some concepts and syntax that i consistently overlook when performing data analysis in python.\n",
      "in the interest of solidifying my understanding of these concepts once and for all and saving you guys a couple of stackoverflow searches, here’s the stuff that i’m always forgetting when working with python, numpy, and pandas.\n",
      "i’ve included a short description and example for each, however for your benefit, i will also include links to videos and other resources that explore each concept more in-depth as well.\n",
      "writing out a for loop every time you need to define some sort of list is tedious, luckily python has a built-in way to address this problem in just one line of code. the syntax can be a little hard to wrap your head around but once you get familiar with this technique you’ll use it fairly often.\n",
      "see the example above and below for how you would normally go about list comprehension with a for loop vs. creating your list with in one simple line with no loops necessary.\n",
      "ever get tired of creating function after function for limited use cases? lambda functions to the rescue! lambda functions are used for creating small, one-time and anonymous function objects in python. basically, they let you create a function, without creating a function.\n",
      "the basic syntax of lambda functions is:\n",
      "note that lambda functions can do everything that regular functions can do, as long as there’s just one expression. check out the simple example below and the upcoming video to get a better feel for the power of lambda functions:\n",
      "once you have a grasp on lambda functions, learning to pair them with the map and filter functions can be a powerful tool.\n",
      "specifically, map takes in a list and transforms it into a new list by performing some sort of operation on each element. in this example, it goes through each element and maps the result of itself times 2 to a new list. note that the list function simply converts the output to list type.\n",
      "the filter function takes in a list and a rule, much like map, however it returns a subset of the original list by comparing each element against the boolean filtering rule.\n",
      "for creating quick and easy numpy arrays, look no further than the arange and linspace functions. each one has their specific purpose, but the appeal here (instead of using range), is that they output numpy arrays, which are typically easier to work with for data science.\n",
      "arange returns evenly spaced values within a given interval. along with a starting and stopping point, you can also define a step size or data type if necessary. note that the stopping point is a ‘cut-off’ value, so it will not be included in the array output.\n",
      "linspace is very similar, but with a slight twist. linspace returns evenly spaced numbers over a specified interval. so given a starting and stopping point, as well as a number of values, linspace will evenly space them out for you in a numpy array. this is especially helpful for data visualizations and declaring axes when plotting.\n",
      "you may have ran into this when dropping a column in pandas or summing values in numpy matrix. if not, then you surely will at some point. let’s use the example of dropping a column for now:\n",
      "i don’t know how many times i wrote this line of code before i actually knew why i was declaring axis what i was. as you can probably deduce from above, set axis to 1 if you want to deal with columns and set it to 0 if you want rows. but why is this? my favorite reasoning, or atleast how i remember this:\n",
      "calling the shape attribute from a pandas dataframe gives us back a tuple with the first value representing the number of rows and the second value representing the number of columns. if you think about how this is indexed in python, rows are at 0 and columns are at 1, much like how we declare our axis value. crazy, right?\n",
      "if you’re familiar with sql, then these concepts will probably come a lot easier for you. anyhow, these functions are essentially just ways to combine dataframes in specific ways. it can be difficult to keep track of which is best to use at which time, so let’s review it.\n",
      "concat allows the user to append one or more dataframes to each other either below or next to it (depending on how you define the axis).\n",
      "merge combines multiple dataframes on specific, common columns that serve as the primary key.\n",
      "join, much like merge, combines two dataframes. however, it joins them based on their indices, rather than some specified column.\n",
      "check out the excellent pandas documentation for specific syntax and more concrete examples, as well as some special cases that you may run into.\n",
      "think of apply as a map function, but made for pandas dataframes or more specifically, for series. if you’re not as familiar, series are pretty similar to numpy arrays for the most part.\n",
      "apply sends a function to every element along a column or row depending on what you specify. you might imagine how useful this can be, especially for formatting and manipulating values across a whole dataframe column, without having to loop at all.\n",
      "last but certainly not least is pivot tables. if you’re familiar with microsoft excel, then you’ve probably heard of pivot tables in some respect. the pandas built-in pivot_table function creates a spreadsheet-style pivot table as a dataframe. note that the levels in the pivot table are stored in multiindex objects on the index and columns of the resulting dataframe.\n",
      "that’s it for now. i hope a couple of these overviews have effectively jogged your memory regarding important yet somewhat tricky methods, functions, and concepts you frequently encounter when using python for data science. personally, i know that even the act of writing these out and trying to explain them in simple terms has helped me out a ton.\n",
      "if you’re interested in receiving my weekly rundown of interesting articles and resources focused on data science, machine learning, and artificial intelligence, then subscribe to self driven data science using the form below!\n",
      "if you enjoyed this post, feel free to hit the clap button and if you’re interested in posts to come, make sure to follow me on medium at the link below — i’ll be writing and shipping every day this month as part of a 30-day challenge.\n",
      "this article was originally published on conordewey.com\n",
      "from a quick cheer to a standing ovation, clap to show how much you enjoyed this story.\n",
      "data scientist & writer | www.conordewey.com\n",
      "sharing concepts, ideas, and codes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check what text column look like.\n",
    "print(articles.loc[1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, \n",
    "# Preprocess the data and obtain the most frequent words across all the articles. \n",
    "# Try to iterate it at least three times, \n",
    "# and in each iteration I will extend the set of stopwords with new ones \n",
    "# based on the words I obtained as frequently occurring but are not particularly informative when I try to understand what the news is about.\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>claps</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Justin Lee</td>\n",
       "      <td>8.3K</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/swlh/chatbots-were-the-next...</td>\n",
       "      <td>Chatbots were the next big thing: what happene...</td>\n",
       "      <td>oh, how the headlines blared:\\nchatbots were t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Conor Dewey</td>\n",
       "      <td>1.4K</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/python-for-data...</td>\n",
       "      <td>Python for Data Science: 8 Concepts You May Ha...</td>\n",
       "      <td>if you’ve ever found yourself looking up the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>William Koehrsen</td>\n",
       "      <td>2.8K</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/automated-featu...</td>\n",
       "      <td>Automated Feature Engineering in Python – Towa...</td>\n",
       "      <td>machine learning is increasingly moving from h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gant Laborde</td>\n",
       "      <td>1.3K</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.freecodecamp.org/machine-learni...</td>\n",
       "      <td>Machine Learning: how to go from Zero to Hero ...</td>\n",
       "      <td>if your understanding of a.i. and machine lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emmanuel Ameisen</td>\n",
       "      <td>935</td>\n",
       "      <td>11</td>\n",
       "      <td>https://blog.insightdatascience.com/reinforcem...</td>\n",
       "      <td>Reinforcement Learning from scratch – Insight ...</td>\n",
       "      <td>want to learn about applied artificial intelli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>Daniel Simmons</td>\n",
       "      <td>3.4K</td>\n",
       "      <td>8</td>\n",
       "      <td>https://itnext.io/you-can-build-a-neural-netwo...</td>\n",
       "      <td>You can build a neural network in JavaScript e...</td>\n",
       "      <td>click here to share this article on linkedin »...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>Eugenio Culurciello</td>\n",
       "      <td>2.8K</td>\n",
       "      <td>13</td>\n",
       "      <td>https://towardsdatascience.com/artificial-inte...</td>\n",
       "      <td>Artificial Intelligence, AI in 2018 and beyond...</td>\n",
       "      <td>these are my opinions on where deep neural net...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>Devin Soni</td>\n",
       "      <td>5.8K</td>\n",
       "      <td>4</td>\n",
       "      <td>https://towardsdatascience.com/spiking-neural-...</td>\n",
       "      <td>Spiking Neural Networks, the Next Generation o...</td>\n",
       "      <td>everyone who has been remotely tuned in to rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>Carlos E. Perez</td>\n",
       "      <td>3.9K</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.com/intuitionmachine/neurons-ar...</td>\n",
       "      <td>Surprise! Neurons are Now More Complex than We...</td>\n",
       "      <td>one of the biggest misconceptions around is th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>Nityesh Agarwal</td>\n",
       "      <td>2.4K</td>\n",
       "      <td>13</td>\n",
       "      <td>https://towardsdatascience.com/wth-does-a-neur...</td>\n",
       "      <td>“WTH does a neural network even learn??” — a n...</td>\n",
       "      <td>i believe, we all have that psychologist/philo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>337 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  author claps  reading_time  \\\n",
       "0             Justin Lee  8.3K            11   \n",
       "1            Conor Dewey  1.4K             7   \n",
       "2       William Koehrsen  2.8K            11   \n",
       "3           Gant Laborde  1.3K             7   \n",
       "4       Emmanuel Ameisen   935            11   \n",
       "..                   ...   ...           ...   \n",
       "332       Daniel Simmons  3.4K             8   \n",
       "333  Eugenio Culurciello  2.8K            13   \n",
       "334           Devin Soni  5.8K             4   \n",
       "335      Carlos E. Perez  3.9K             7   \n",
       "336      Nityesh Agarwal  2.4K            13   \n",
       "\n",
       "                                                  link  \\\n",
       "0    https://medium.com/swlh/chatbots-were-the-next...   \n",
       "1    https://towardsdatascience.com/python-for-data...   \n",
       "2    https://towardsdatascience.com/automated-featu...   \n",
       "3    https://medium.freecodecamp.org/machine-learni...   \n",
       "4    https://blog.insightdatascience.com/reinforcem...   \n",
       "..                                                 ...   \n",
       "332  https://itnext.io/you-can-build-a-neural-netwo...   \n",
       "333  https://towardsdatascience.com/artificial-inte...   \n",
       "334  https://towardsdatascience.com/spiking-neural-...   \n",
       "335  https://medium.com/intuitionmachine/neurons-ar...   \n",
       "336  https://towardsdatascience.com/wth-does-a-neur...   \n",
       "\n",
       "                                                 title  \\\n",
       "0    Chatbots were the next big thing: what happene...   \n",
       "1    Python for Data Science: 8 Concepts You May Ha...   \n",
       "2    Automated Feature Engineering in Python – Towa...   \n",
       "3    Machine Learning: how to go from Zero to Hero ...   \n",
       "4    Reinforcement Learning from scratch – Insight ...   \n",
       "..                                                 ...   \n",
       "332  You can build a neural network in JavaScript e...   \n",
       "333  Artificial Intelligence, AI in 2018 and beyond...   \n",
       "334  Spiking Neural Networks, the Next Generation o...   \n",
       "335  Surprise! Neurons are Now More Complex than We...   \n",
       "336  “WTH does a neural network even learn??” — a n...   \n",
       "\n",
       "                                                  text  \n",
       "0    oh, how the headlines blared:\\nchatbots were t...  \n",
       "1    if you’ve ever found yourself looking up the s...  \n",
       "2    machine learning is increasingly moving from h...  \n",
       "3    if your understanding of a.i. and machine lear...  \n",
       "4    want to learn about applied artificial intelli...  \n",
       "..                                                 ...  \n",
       "332  click here to share this article on linkedin »...  \n",
       "333  these are my opinions on where deep neural net...  \n",
       "334  everyone who has been remotely tuned in to rec...  \n",
       "335  one of the biggest misconceptions around is th...  \n",
       "336  i believe, we all have that psychologist/philo...  \n",
       "\n",
       "[337 rows x 6 columns]"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change \"text\" column to lowercase \n",
    "articles[\"text\"] = articles[\"text\"].str.lower()\n",
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>claps</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>split</th>\n",
       "      <th>split_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Justin Lee</td>\n",
       "      <td>8.3K</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/swlh/chatbots-were-the-next...</td>\n",
       "      <td>Chatbots were the next big thing: what happene...</td>\n",
       "      <td>oh, how the headlines blared:\\nchatbots were t...</td>\n",
       "      <td>[oh,, headlines, blared:, chatbots, next, big,...</td>\n",
       "      <td>oh, headlines blared: chatbots next big thing....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Conor Dewey</td>\n",
       "      <td>1.4K</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/python-for-data...</td>\n",
       "      <td>Python for Data Science: 8 Concepts You May Ha...</td>\n",
       "      <td>if you’ve ever found yourself looking up the s...</td>\n",
       "      <td>[you’ve, ever, found, looking, question,, conc...</td>\n",
       "      <td>you’ve ever found looking question, concept, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>William Koehrsen</td>\n",
       "      <td>2.8K</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/automated-featu...</td>\n",
       "      <td>Automated Feature Engineering in Python – Towa...</td>\n",
       "      <td>machine learning is increasingly moving from h...</td>\n",
       "      <td>[machine, learning, increasingly, moving, hand...</td>\n",
       "      <td>machine learning increasingly moving hand-desi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gant Laborde</td>\n",
       "      <td>1.3K</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.freecodecamp.org/machine-learni...</td>\n",
       "      <td>Machine Learning: how to go from Zero to Hero ...</td>\n",
       "      <td>if your understanding of a.i. and machine lear...</td>\n",
       "      <td>[understanding, a.i., machine, learning, big, ...</td>\n",
       "      <td>understanding a.i. machine learning big questi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emmanuel Ameisen</td>\n",
       "      <td>935</td>\n",
       "      <td>11</td>\n",
       "      <td>https://blog.insightdatascience.com/reinforcem...</td>\n",
       "      <td>Reinforcement Learning from scratch – Insight ...</td>\n",
       "      <td>want to learn about applied artificial intelli...</td>\n",
       "      <td>[want, learn, applied, artificial, intelligenc...</td>\n",
       "      <td>want learn applied artificial intelligence lea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author claps  reading_time  \\\n",
       "0        Justin Lee  8.3K            11   \n",
       "1       Conor Dewey  1.4K             7   \n",
       "2  William Koehrsen  2.8K            11   \n",
       "3      Gant Laborde  1.3K             7   \n",
       "4  Emmanuel Ameisen   935            11   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://medium.com/swlh/chatbots-were-the-next...   \n",
       "1  https://towardsdatascience.com/python-for-data...   \n",
       "2  https://towardsdatascience.com/automated-featu...   \n",
       "3  https://medium.freecodecamp.org/machine-learni...   \n",
       "4  https://blog.insightdatascience.com/reinforcem...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Chatbots were the next big thing: what happene...   \n",
       "1  Python for Data Science: 8 Concepts You May Ha...   \n",
       "2  Automated Feature Engineering in Python – Towa...   \n",
       "3  Machine Learning: how to go from Zero to Hero ...   \n",
       "4  Reinforcement Learning from scratch – Insight ...   \n",
       "\n",
       "                                                text  \\\n",
       "0  oh, how the headlines blared:\\nchatbots were t...   \n",
       "1  if you’ve ever found yourself looking up the s...   \n",
       "2  machine learning is increasingly moving from h...   \n",
       "3  if your understanding of a.i. and machine lear...   \n",
       "4  want to learn about applied artificial intelli...   \n",
       "\n",
       "                                               split  \\\n",
       "0  [oh,, headlines, blared:, chatbots, next, big,...   \n",
       "1  [you’ve, ever, found, looking, question,, conc...   \n",
       "2  [machine, learning, increasingly, moving, hand...   \n",
       "3  [understanding, a.i., machine, learning, big, ...   \n",
       "4  [want, learn, applied, artificial, intelligenc...   \n",
       "\n",
       "                                         split_final  \n",
       "0  oh, headlines blared: chatbots next big thing....  \n",
       "1  you’ve ever found looking question, concept, s...  \n",
       "2  machine learning increasingly moving hand-desi...  \n",
       "3  understanding a.i. machine learning big questi...  \n",
       "4  want learn applied artificial intelligence lea...  "
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing the stopwords while keeping the string format and not create list.\n",
    "\n",
    "articles['split'] = articles[\"text\"].apply(lambda x: x.split())\n",
    "\n",
    "# Remove the stopwrods. \n",
    "\n",
    "stop_words = list(stopwords.words(\"english\"))\n",
    "\n",
    "articles['split'] = articles['split'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "\n",
    "# Get back the single string format.\n",
    "articles['split_final'] = articles['split'].apply(lambda x: ' '.join(x))\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(337, 20393)"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the most frequent words across all the articles.\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize an object. \n",
    "vect = CountVectorizer()\n",
    "\n",
    "# Create the representation.\n",
    "\n",
    "article_counts = vect.fit_transform(articles['split_final'])\n",
    "\n",
    "# Check the size of the resulting data.\n",
    "\n",
    "article_counts.shape\n",
    "\n",
    "# 337 rows corresponding to the original articles, \n",
    "# and 20393 columns for the words that appear in at least 1 article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<337x20393 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 187415 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>00000</th>\n",
       "      <th>0001</th>\n",
       "      <th>0002which</th>\n",
       "      <th>00061</th>\n",
       "      <th>00078</th>\n",
       "      <th>000assuming</th>\n",
       "      <th>000s</th>\n",
       "      <th>...</th>\n",
       "      <th>记录一下</th>\n",
       "      <th>说实话</th>\n",
       "      <th>还是看代码比较有感觉</th>\n",
       "      <th>还是要多对照着代码看</th>\n",
       "      <th>这一阵为了工作上的关系</th>\n",
       "      <th>这个步骤并不适合各位读博士发论文的同学们</th>\n",
       "      <th>这样前前后后</th>\n",
       "      <th>都没读完而且得到到信息也很有限</th>\n",
       "      <th>除了集体智慧编程这本书之外基本没怎么看过机器学习的人来说</th>\n",
       "      <th>高久力</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20393 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0000  00000  0001  0002which  00061  00078  000assuming  000s  \\\n",
       "0   0    1     0      0     0          0      0      0            0     0   \n",
       "1   0    0     0      0     0          0      0      0            0     0   \n",
       "2   0    0     0      0     0          0      0      0            0     0   \n",
       "3   0    0     0      0     0          0      0      0            0     0   \n",
       "4   0    0     0      0     0          0      0      0            0     0   \n",
       "\n",
       "   ...  记录一下  说实话  还是看代码比较有感觉  还是要多对照着代码看  这一阵为了工作上的关系  这个步骤并不适合各位读博士发论文的同学们  \\\n",
       "0  ...     0    0           0           0            0                     0   \n",
       "1  ...     0    0           0           0            0                     0   \n",
       "2  ...     0    0           0           0            0                     0   \n",
       "3  ...     0    0           0           0            0                     0   \n",
       "4  ...     0    0           0           0            0                     0   \n",
       "\n",
       "   这样前前后后  都没读完而且得到到信息也很有限  除了集体智慧编程这本书之外基本没怎么看过机器学习的人来说  高久力  \n",
       "0       0                0                             0    0  \n",
       "1       0                0                             0    0  \n",
       "2       0                0                             0    0  \n",
       "3       0                0                             0    0  \n",
       "4       0                0                             0    0  \n",
       "\n",
       "[5 rows x 20393 columns]"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert it to a dataframe\n",
    "\n",
    "article_counts_df = pd.DataFrame(article_counts.toarray(), columns=vect.get_feature_names())\n",
    "\n",
    "article_counts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 article\n"
     ]
    }
   ],
   "source": [
    "for i in range (1,337):\n",
    "    if \"除了集体智慧编程这本书之外基本没怎么看过机器学习的人来说\" in articles.loc[i].split_final:\n",
    "        print (i, \"article\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['这一阵为了工作上的关系,花了点时间学习了一下lda算法,说实话,对于我这个学cs而非学数学的人来说,除了集体智慧编程这本书之外基本没怎么看过机器学习的人来说,一开始还真是摸不太到门道,前前后后快要四个月了,算是基本了解了这个算法的实现,记录一下,也供后来人快速入门做个参考。', '一开始直接就下了blei的原始的那篇论文来看,但是看了个开头就被dirichlet分布和几个数学公式打倒,然后因为专心在写项目中的具体的代码,也就先放下了。但是因为发现完全忘记了本科学的概率和统计的内容,只好回头去看大学时候概率论的教材,发现早不知道借给谁了,于是上网买了本,花了几天时间大致回顾了一遍概率论的知识,什么贝叶斯全概率公式,正态分布,二项分布之类的。后来晚上没事儿的时候,去水木的ai版转了转,了解到了machine', 'learning的圣经prml,考虑到反正也是要长期学习了,搞了电子版,同时上淘宝买了个打印胶装的版本。春节里每天晚上看一点儿,扫了一下前两章,再次回顾了一下基本数学知识,然后了解了下贝叶斯学派那种采用共轭先验来建模的方式。于是再次尝试回头去看blei的那篇论文,发现还是看不太懂,于是又放下了。然后某天tony让我准备准备给复旦的同学们share一下我们项目中lda的使用,为了不露怯,又去翻论文,正好看到science上这篇topic', 'models', 'vs.', 'unstructured', 'data的科普性质的文章,翻了一遍之后,再去prml里看了一遍graphic', 'models那一张,觉得对于lda想解决的问题和方法了解了更清楚了。之后从search', 'engine里搜到这篇文章,然后根据推荐读了一部分的gibbs', 'sampling', 'uninitiated。之后忘了怎么又搜到了mark', 'steyvers和tom', 'griffiths合著的probabilistic', 'topic', 'models,在某个周末往返北京的飞机上读完了,觉得基本上模型训练过程也明白了。再之后就是读了一下这个最简版的lda', 'gibbs', 'sampling的实现,再回过头读了一下plda的源码,基本上算是对lda有了个相对清楚的了解。', '这样前前后后,也过去了三个月,其实不少时间都是浪费掉的,比如blei的论文在没有任何相关知识的情况下一开始读了好几次,都没读完而且得到到信息也很有限,如果重新总结一下,我觉得对于我们这些门外汉程序员来说,想了解lda大概需要这些知识:', '基本上这样一圈下来,基本概念和算法实现都应该搞定了,当然,数学证明其实没那么容易就搞定,但是对于工程师来说,先把这些搞定就能干活了,这个步骤并不适合各位读博士发论文的同学们,但是这样先看看也比较容易对于这些数学问题的兴趣,不然,成天对这符号和数学公式,没有整块业余时间的我是觉得还是容易退缩放弃的。', '发现作为工程师来说,还是看代码比较有感觉,看实际应用的实例比较有感觉,看来不能把大部分时间花在prml上,还是要多对照着代码看。', 'quick', 'cheer', 'standing', 'ovation,', 'clap', 'show', 'much', 'enjoyed', 'story.', 'facebook', 'messenger', '&', 'chatbot,', 'machine', 'learning', '&', 'big', 'data', '生命如此短暂,掌握技艺却要如此长久']\n"
     ]
    }
   ],
   "source": [
    "print(articles.loc[23].split)\n",
    "# Interesting, There is an article in Chinese. and it was not be splited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "高久力                1\n",
       "programatically    1\n",
       "diffe              1\n",
       "programing         1\n",
       "diferencias        1\n",
       "diferenciar        1\n",
       "progre             1\n",
       "dies               1\n",
       "dient              1\n",
       "prohibitive        1\n",
       "prohibitively      1\n",
       "projections        1\n",
       "profitable         1\n",
       "projetos           1\n",
       "dictation          1\n",
       "dictated           1\n",
       "promoted           1\n",
       "promotes           1\n",
       "diat               1\n",
       "promotion          1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count = article_counts_df.sum(axis=0).sort_values()\n",
    "word_count[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6649"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = 0\n",
    "for n in word_count.values:\n",
    "    if n ==1:\n",
    "        sum+=1\n",
    "sum\n",
    "\n",
    "## There are 6649 words only occur once across all the articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "learning    2837\n",
       "data        2646\n",
       "one         1914\n",
       "it          1904\n",
       "network     1794\n",
       "machine     1644\n",
       "like        1623\n",
       "neural      1529\n",
       "time        1344\n",
       "use         1283\n",
       "would       1250\n",
       "ai          1216\n",
       "also        1178\n",
       "model       1171\n",
       "much        1062\n",
       "deep        1061\n",
       "using       1049\n",
       "new          988\n",
       "training     945\n",
       "image        936\n",
       "human        904\n",
       "make         895\n",
       "way          893\n",
       "we           880\n",
       "get          857\n",
       "you          847\n",
       "could        842\n",
       "people       838\n",
       "us           831\n",
       "need         830\n",
       "dtype: int64"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count = article_counts_df.sum(axis=0).sort_values(ascending = False)\n",
    "word_count[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "learning    2837\n",
       "data        2646\n",
       "one         1914\n",
       "network     1794\n",
       "machine     1644\n",
       "like        1623\n",
       "neural      1529\n",
       "time        1344\n",
       "use         1283\n",
       "ai          1216\n",
       "also        1178\n",
       "model       1171\n",
       "much        1062\n",
       "deep        1061\n",
       "using       1049\n",
       "new          988\n",
       "training     945\n",
       "image        936\n",
       "human        904\n",
       "make         895\n",
       "way          893\n",
       "get          857\n",
       "people       838\n",
       "us           831\n",
       "need         830\n",
       "first        819\n",
       "many         808\n",
       "see          773\n",
       "example      771\n",
       "work         767\n",
       "dtype: int64"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate the second time. Remove [\"it\",\"could\",\"would\"]\n",
    "\n",
    "stop_words_new = stop_words + [\"it\",\"could\",\"would\"]\n",
    "\n",
    "vect_new = CountVectorizer(stop_words = stop_words_new)\n",
    "\n",
    "article_counts_new = vect_new.fit_transform(articles['split_final'])\n",
    "\n",
    "# Convert it to dataframe\n",
    "\n",
    "article_counts_df_new = pd.DataFrame(article_counts_new.toarray(), columns=vect_new.get_feature_names())\n",
    "\n",
    "\n",
    "word_count_new = article_counts_df_new.sum(axis=0).sort_values(ascending = False)\n",
    "word_count_new[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you in stop words\n",
      "we in stop words\n",
      "if in stop words\n",
      "not in the word_count_new \n",
      "not in the word_count_new \n",
      "not in the word_count_new \n"
     ]
    }
   ],
   "source": [
    "test_list = [\"you\",\"we\",\"if\"]\n",
    "\n",
    "for word in test_list:\n",
    "    if word in stop_words:\n",
    "        print (word, \"in stop words\")\n",
    "\n",
    "# words in test_list all in stop_words, but it all occurs when I first iterate to create the word_count.\n",
    "        \n",
    "for word in test_list:\n",
    "    try: \n",
    "        word_count_new.loc[word]\n",
    "    except:\n",
    "        print (\"not in the word_count_new\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "learning     2837\n",
       "data         2646\n",
       "one          1914\n",
       "network      1794\n",
       "machine      1644\n",
       "like         1623\n",
       "neural       1529\n",
       "time         1344\n",
       "use          1283\n",
       "ai           1216\n",
       "model        1171\n",
       "deep         1061\n",
       "using        1049\n",
       "new           988\n",
       "training      945\n",
       "image         936\n",
       "human         904\n",
       "make          895\n",
       "way           893\n",
       "get           857\n",
       "need          830\n",
       "first         819\n",
       "see           773\n",
       "example       771\n",
       "networks      767\n",
       "work          767\n",
       "even          762\n",
       "used          754\n",
       "learn         743\n",
       "different     731\n",
       "dtype: int64"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate the Third time.\n",
    "\n",
    "stop_words_3 = stop_words_new + [\"many\",\"us\",\"also\",\"people\",\"much\"]\n",
    "\n",
    "vect_3 = CountVectorizer(stop_words = stop_words_3)\n",
    "\n",
    "article_counts_3 = vect_3.fit_transform(articles['split_final'])\n",
    "\n",
    "# Convert it to dataframe\n",
    "\n",
    "article_counts_df_3 = pd.DataFrame(article_counts_3.toarray(), columns=vect_3.get_feature_names())\n",
    "\n",
    "\n",
    "word_count_3 = article_counts_df_3.sum(axis=0).sort_values(ascending = False)\n",
    "word_count_3[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the second step, perform topic modeling on the data with specifying four topics to be extracted. Based\n",
    "# on looking at the top 15 words from each topic, can you differentiate them and explain how they are\n",
    "# different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "LDA = LatentDirichletAllocation(n_components = 4, random_state = 42)\n",
    "\n",
    "LDA_results = LDA.fit_transform(article_counts_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.25038791, 42.12387408,  0.25040504, ...,  0.25000181,\n",
       "         0.25000181,  0.25329847],\n",
       "       [ 0.25000144,  1.46722964,  0.25000068, ...,  0.25000869,\n",
       "         0.25000869,  0.25000227],\n",
       "       [ 0.28118556, 37.61910558,  0.25000018, ...,  0.25000262,\n",
       "         0.25000262,  0.25121443],\n",
       "       [ 2.2184251 , 70.78979069,  4.2495941 , ...,  1.24998688,\n",
       "         1.24998688,  1.24548483]])"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The relavent to each topic of Each word in each article\n",
    "LDA.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['layer', 'learn', 'function', 'like', 'time', 'using', 'use', 'training', 'model', 'one', 'neural', 'machine', 'network', 'data', 'learning']\n",
      "['object', 'features', 'feature', 'et', 'see', 'que', 'bounding', 'boxes', 'like', 'region', 'la', 'one', 'image', 'de', 'cnn']\n",
      "['use', 'way', 'world', 'even', 'technology', 'information', 'may', 'time', 'new', 'intelligence', 'one', 'like', 'data', 'human', 'ai']\n",
      "['game', 'training', 'part', 'model', 'image', 'use', 'time', 'machine', 'deep', 'like', 'one', 'data', 'neural', 'network', 'learning']\n"
     ]
    }
   ],
   "source": [
    "for topic, component in enumerate(LDA.components_):\n",
    "\n",
    "    words_sorted = np.argsort(component)[-15:]\n",
    "    \n",
    "    print([vect_3.get_feature_names()[i] for i in words_sorted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 \n",
    "# Maybe articles about neural network machine leaning, maybe more theoretically because there are words like \"layer\"\n",
    "\n",
    "# 1\n",
    "# Maybe articles about CNN to analyze image. \n",
    "\n",
    "# 2\n",
    "# Maybe articles about new technology about AI \n",
    "\n",
    "# 3 \n",
    "# Maybe articles about neural network deep leaning in game and image, maybe more about application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
