{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "v2SbC_gepMiB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from a csv file \"MP2_Data.csv\".\n",
    "\n",
    "data = pd.read_csv(\"MP2_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "id": "bNthvuilqY4S",
    "outputId": "2e022a4d-0fb0-4498-dfbf-3f70ccccb8b1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Week2_Quiz1</th>\n",
       "      <th>Week3_MP1</th>\n",
       "      <th>Week3_PR1</th>\n",
       "      <th>Week5_MP2</th>\n",
       "      <th>Week5_PR2</th>\n",
       "      <th>Week7_MP3</th>\n",
       "      <th>Week7_PR3</th>\n",
       "      <th>Week4_Quiz2</th>\n",
       "      <th>Week6_Quiz3</th>\n",
       "      <th>...</th>\n",
       "      <th>Week7_Stat3</th>\n",
       "      <th>Week8_Stat0</th>\n",
       "      <th>Week8_Stat1</th>\n",
       "      <th>Week8_Stat2</th>\n",
       "      <th>Week8_Stat3</th>\n",
       "      <th>Week9_Stat0</th>\n",
       "      <th>Week9_Stat1</th>\n",
       "      <th>Week9_Stat2</th>\n",
       "      <th>Week9_Stat3</th>\n",
       "      <th>Grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ML-2020-1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.09</td>\n",
       "      <td>5.00</td>\n",
       "      <td>21.88</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ML-2020-2</td>\n",
       "      <td>3.33</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.83</td>\n",
       "      <td>5.00</td>\n",
       "      <td>22.27</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ML-2020-3</td>\n",
       "      <td>1.67</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.22</td>\n",
       "      <td>5.00</td>\n",
       "      <td>27.05</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ML-2020-4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>31.02</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ML-2020-6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.17</td>\n",
       "      <td>4.93</td>\n",
       "      <td>15.91</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.67</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Week2_Quiz1  Week3_MP1  Week3_PR1  Week5_MP2  Week5_PR2  \\\n",
       "0  ML-2020-1         5.00       15.0        5.0      16.09       5.00   \n",
       "1  ML-2020-2         3.33       15.0        5.0      17.83       5.00   \n",
       "2  ML-2020-3         1.67       13.0        5.0      15.22       5.00   \n",
       "3  ML-2020-4         2.50       14.0        5.0      10.00       5.00   \n",
       "4  ML-2020-6         0.00       15.0        5.0      12.17       4.93   \n",
       "\n",
       "   Week7_MP3  Week7_PR3  Week4_Quiz2  Week6_Quiz3  ...  Week7_Stat3  \\\n",
       "0      21.88        5.0         5.00          5.0  ...            0   \n",
       "1      22.27        5.0         4.00          5.0  ...            8   \n",
       "2      27.05        2.5         5.00          5.0  ...            0   \n",
       "3      31.02        5.0         3.13          5.0  ...            4   \n",
       "4      15.91        5.0         4.67          5.0  ...            6   \n",
       "\n",
       "   Week8_Stat0  Week8_Stat1  Week8_Stat2  Week8_Stat3  Week9_Stat0  \\\n",
       "0            5            4            0            4            8   \n",
       "1            5            2            0            0           25   \n",
       "2            8            2            0            0            9   \n",
       "3           10            0            0            0            7   \n",
       "4            8            5            1            1            5   \n",
       "\n",
       "   Week9_Stat1  Week9_Stat2  Week9_Stat3  Grade  \n",
       "0            6            1            0      4  \n",
       "1            3            2            5      4  \n",
       "2            0            1            0      3  \n",
       "3            6            0            0      3  \n",
       "4            3            1            0      2  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vZB4cetrsOG"
   },
   "source": [
    "# Descriptive analysis\n",
    "Try to understand the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ZNMqxhYqhdq",
    "outputId": "154f431f-442b-4619-e149-2e6d155f3d9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 107 entries, 0 to 106\n",
      "Data columns (total 48 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   ID           107 non-null    object \n",
      " 1   Week2_Quiz1  107 non-null    float64\n",
      " 2   Week3_MP1    107 non-null    float64\n",
      " 3   Week3_PR1    107 non-null    float64\n",
      " 4   Week5_MP2    107 non-null    float64\n",
      " 5   Week5_PR2    107 non-null    float64\n",
      " 6   Week7_MP3    107 non-null    float64\n",
      " 7   Week7_PR3    107 non-null    float64\n",
      " 8   Week4_Quiz2  107 non-null    float64\n",
      " 9   Week6_Quiz3  107 non-null    float64\n",
      " 10  Week8_Total  107 non-null    float64\n",
      " 11  Week1_Stat0  107 non-null    int64  \n",
      " 12  Week1_Stat1  107 non-null    int64  \n",
      " 13  Week1_Stat2  107 non-null    int64  \n",
      " 14  Week1_Stat3  107 non-null    int64  \n",
      " 15  Week2_Stat0  107 non-null    int64  \n",
      " 16  Week2_Stat1  107 non-null    int64  \n",
      " 17  Week2_Stat2  107 non-null    int64  \n",
      " 18  Week2_Stat3  107 non-null    int64  \n",
      " 19  Week3_Stat0  107 non-null    int64  \n",
      " 20  Week3_Stat1  107 non-null    int64  \n",
      " 21  Week3_Stat2  107 non-null    int64  \n",
      " 22  Week3_Stat3  107 non-null    int64  \n",
      " 23  Week4_Stat0  107 non-null    int64  \n",
      " 24  Week4_Stat1  107 non-null    int64  \n",
      " 25  Week4_Stat2  107 non-null    int64  \n",
      " 26  Week4_Stat3  107 non-null    int64  \n",
      " 27  Week5_Stat0  107 non-null    int64  \n",
      " 28  Week5_Stat1  107 non-null    int64  \n",
      " 29  Week5_Stat2  107 non-null    int64  \n",
      " 30  Week5_Stat3  107 non-null    int64  \n",
      " 31  Week6_Stat0  107 non-null    int64  \n",
      " 32  Week6_Stat1  107 non-null    int64  \n",
      " 33  Week6_Stat2  107 non-null    int64  \n",
      " 34  Week6_Stat3  107 non-null    int64  \n",
      " 35  Week7_Stat0  107 non-null    int64  \n",
      " 36  Week7_Stat1  107 non-null    int64  \n",
      " 37  Week7_Stat2  107 non-null    int64  \n",
      " 38  Week7_Stat3  107 non-null    int64  \n",
      " 39  Week8_Stat0  107 non-null    int64  \n",
      " 40  Week8_Stat1  107 non-null    int64  \n",
      " 41  Week8_Stat2  107 non-null    int64  \n",
      " 42  Week8_Stat3  107 non-null    int64  \n",
      " 43  Week9_Stat0  107 non-null    int64  \n",
      " 44  Week9_Stat1  107 non-null    int64  \n",
      " 45  Week9_Stat2  107 non-null    int64  \n",
      " 46  Week9_Stat3  107 non-null    int64  \n",
      " 47  Grade        107 non-null    int64  \n",
      "dtypes: float64(10), int64(37), object(1)\n",
      "memory usage: 40.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()\n",
    "\n",
    "# Only numeric variables except for ID\n",
    "# No missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "EQWpHRHksUw7",
    "outputId": "240729f9-1777-4680-c03e-4eb8d3ff39d8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Week2_Quiz1</th>\n",
       "      <th>Week3_MP1</th>\n",
       "      <th>Week3_PR1</th>\n",
       "      <th>Week5_MP2</th>\n",
       "      <th>Week5_PR2</th>\n",
       "      <th>Week7_MP3</th>\n",
       "      <th>Week7_PR3</th>\n",
       "      <th>Week4_Quiz2</th>\n",
       "      <th>Week6_Quiz3</th>\n",
       "      <th>Week8_Total</th>\n",
       "      <th>...</th>\n",
       "      <th>Week7_Stat3</th>\n",
       "      <th>Week8_Stat0</th>\n",
       "      <th>Week8_Stat1</th>\n",
       "      <th>Week8_Stat2</th>\n",
       "      <th>Week8_Stat3</th>\n",
       "      <th>Week9_Stat0</th>\n",
       "      <th>Week9_Stat1</th>\n",
       "      <th>Week9_Stat2</th>\n",
       "      <th>Week9_Stat3</th>\n",
       "      <th>Grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.406636</td>\n",
       "      <td>7.949626</td>\n",
       "      <td>2.803738</td>\n",
       "      <td>9.237757</td>\n",
       "      <td>2.844673</td>\n",
       "      <td>14.481869</td>\n",
       "      <td>2.383178</td>\n",
       "      <td>2.609439</td>\n",
       "      <td>2.663551</td>\n",
       "      <td>47.380467</td>\n",
       "      <td>...</td>\n",
       "      <td>1.252336</td>\n",
       "      <td>10.514019</td>\n",
       "      <td>3.130841</td>\n",
       "      <td>1.112150</td>\n",
       "      <td>0.355140</td>\n",
       "      <td>7.663551</td>\n",
       "      <td>1.607477</td>\n",
       "      <td>1.093458</td>\n",
       "      <td>0.046729</td>\n",
       "      <td>2.074766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.000317</td>\n",
       "      <td>6.892312</td>\n",
       "      <td>2.493158</td>\n",
       "      <td>8.640610</td>\n",
       "      <td>2.482099</td>\n",
       "      <td>14.080211</td>\n",
       "      <td>2.437501</td>\n",
       "      <td>2.229419</td>\n",
       "      <td>2.414359</td>\n",
       "      <td>41.035589</td>\n",
       "      <td>...</td>\n",
       "      <td>2.399267</td>\n",
       "      <td>15.563846</td>\n",
       "      <td>4.841028</td>\n",
       "      <td>3.658351</td>\n",
       "      <td>1.191577</td>\n",
       "      <td>9.277630</td>\n",
       "      <td>2.687346</td>\n",
       "      <td>3.368928</td>\n",
       "      <td>0.483368</td>\n",
       "      <td>1.993863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.330000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.870000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>15.910000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.170000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>71.530000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.170000</td>\n",
       "      <td>14.305000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>18.045000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>27.440000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.710000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>83.550000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>99.710000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Week2_Quiz1   Week3_MP1   Week3_PR1   Week5_MP2   Week5_PR2  \\\n",
       "count   107.000000  107.000000  107.000000  107.000000  107.000000   \n",
       "mean      2.406636    7.949626    2.803738    9.237757    2.844673   \n",
       "std       2.000317    6.892312    2.493158    8.640610    2.482099   \n",
       "min       0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%       0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%       3.330000   12.000000    5.000000   10.870000    5.000000   \n",
       "75%       4.170000   14.305000    5.000000   18.045000    5.000000   \n",
       "max       5.000000   15.000000    5.000000   20.000000    5.000000   \n",
       "\n",
       "        Week7_MP3   Week7_PR3  Week4_Quiz2  Week6_Quiz3  Week8_Total  ...  \\\n",
       "count  107.000000  107.000000   107.000000   107.000000   107.000000  ...   \n",
       "mean    14.481869    2.383178     2.609439     2.663551    47.380467  ...   \n",
       "std     14.080211    2.437501     2.229419     2.414359    41.035589  ...   \n",
       "min      0.000000    0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%      0.000000    0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%     15.910000    2.500000     3.170000     4.000000    71.530000  ...   \n",
       "75%     27.440000    5.000000     4.710000     5.000000    83.550000  ...   \n",
       "max     35.000000    5.000000     5.000000     5.000000    99.710000  ...   \n",
       "\n",
       "       Week7_Stat3  Week8_Stat0  Week8_Stat1  Week8_Stat2  Week8_Stat3  \\\n",
       "count   107.000000   107.000000   107.000000   107.000000   107.000000   \n",
       "mean      1.252336    10.514019     3.130841     1.112150     0.355140   \n",
       "std       2.399267    15.563846     4.841028     3.658351     1.191577   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     5.000000     0.000000     0.000000     0.000000   \n",
       "75%       2.000000    14.000000     5.000000     0.000000     0.000000   \n",
       "max      12.000000    90.000000    27.000000    22.000000     9.000000   \n",
       "\n",
       "       Week9_Stat0  Week9_Stat1  Week9_Stat2  Week9_Stat3       Grade  \n",
       "count   107.000000   107.000000   107.000000   107.000000  107.000000  \n",
       "mean      7.663551     1.607477     1.093458     0.046729    2.074766  \n",
       "std       9.277630     2.687346     3.368928     0.483368    1.993863  \n",
       "min       0.000000     0.000000     0.000000     0.000000    0.000000  \n",
       "25%       1.000000     0.000000     0.000000     0.000000    0.000000  \n",
       "50%       5.000000     0.000000     0.000000     0.000000    3.000000  \n",
       "75%      11.000000     2.000000     0.500000     0.000000    4.000000  \n",
       "max      62.000000    12.000000    25.000000     5.000000    5.000000  \n",
       "\n",
       "[8 rows x 47 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the statistical measures of the numeric columns\n",
    "\n",
    "data.describe()\n",
    "\n",
    "## compared to other columns, there are very high Max value of Week8_Total, Week8_Stat0,Week9_Stat0. So maybe Week1_Stat0 to Week9_Stat0 all have high max value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MPWXoEkVg6Bz",
    "outputId": "d52d6b74-7647-415b-c0fe-9594d1030df9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Week1_Stat0 Max:  27\n",
      "Week1_Stat0 Mean:  6.785046728971962\n",
      "\n",
      "\n",
      "Week2_Stat0 Max:  104\n",
      "Week2_Stat0 Mean:  16.88785046728972\n",
      "\n",
      "\n",
      "Week3_Stat0 Max:  108\n",
      "Week3_Stat0 Mean:  31.72897196261682\n",
      "\n",
      "\n",
      "Week4_Stat0 Max:  240\n",
      "Week4_Stat0 Mean:  41.91588785046729\n",
      "\n",
      "\n",
      "Week5_Stat0 Max:  185\n",
      "Week5_Stat0 Mean:  26.074766355140188\n",
      "\n",
      "\n",
      "Week6_Stat0 Max:  208\n",
      "Week6_Stat0 Mean:  37.60747663551402\n",
      "\n",
      "\n",
      "Week7_Stat0 Max:  145\n",
      "Week7_Stat0 Mean:  16.35514018691589\n",
      "\n",
      "\n",
      "Week8_Stat0 Max:  90\n",
      "Week8_Stat0 Mean:  10.514018691588785\n",
      "\n",
      "\n",
      "Week9_Stat0 Max:  62\n",
      "Week9_Stat0 Mean:  7.663551401869159\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check Week1_Stat0 to Week9_Stat0 max value and mean value\n",
    "\n",
    "for i in range (1,10):\n",
    "  col = f'Week{i}_Stat0'\n",
    "  print (col,\"Max: \", data[col].max())\n",
    "  print (col,\"Mean: \", data[col].mean())\n",
    "  print (\"\\n\")\n",
    "\n",
    "# There is a big difference between the maximum value and the mean value of some weeks stat0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qgv6NBcvvnJr",
    "outputId": "bc8184df-3ce5-4fae-e31a-e3e4320533f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    48\n",
      "4    24\n",
      "3    17\n",
      "5    13\n",
      "2     5\n",
      "Name: Grade, dtype: int64\n",
      "\n",
      "\n",
      "Mean: 2.074766355140187\n"
     ]
    }
   ],
   "source": [
    "# check the target/outcome (y)\n",
    "\n",
    "# there are 5 classes, nearly half students are in the class grade 0.\n",
    "print (data.Grade.value_counts())\n",
    "\n",
    "print (\"\\n\")\n",
    "# check the mean\n",
    "print (\"Mean:\",data.Grade.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "KrratFUZv7ZH",
    "outputId": "5a4078b7-7a21-423e-f295-5a0d85dfafa4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Week2_Quiz1</th>\n",
       "      <th>Week3_MP1</th>\n",
       "      <th>Week3_PR1</th>\n",
       "      <th>Week5_MP2</th>\n",
       "      <th>Week5_PR2</th>\n",
       "      <th>Week7_MP3</th>\n",
       "      <th>Week7_PR3</th>\n",
       "      <th>Week4_Quiz2</th>\n",
       "      <th>Week6_Quiz3</th>\n",
       "      <th>Week8_Total</th>\n",
       "      <th>...</th>\n",
       "      <th>Week7_Stat2</th>\n",
       "      <th>Week7_Stat3</th>\n",
       "      <th>Week8_Stat0</th>\n",
       "      <th>Week8_Stat1</th>\n",
       "      <th>Week8_Stat2</th>\n",
       "      <th>Week8_Stat3</th>\n",
       "      <th>Week9_Stat0</th>\n",
       "      <th>Week9_Stat1</th>\n",
       "      <th>Week9_Stat2</th>\n",
       "      <th>Week9_Stat3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grade</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.885208</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.226458</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.490625</td>\n",
       "      <td>0.302083</td>\n",
       "      <td>3.154375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>2.895833</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>1.062500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>1.791667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.502000</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.782000</td>\n",
       "      <td>4.986000</td>\n",
       "      <td>14.718000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.678000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>64.766000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.872941</td>\n",
       "      <td>13.529412</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.888235</td>\n",
       "      <td>4.994118</td>\n",
       "      <td>22.905294</td>\n",
       "      <td>3.970588</td>\n",
       "      <td>4.477059</td>\n",
       "      <td>4.529412</td>\n",
       "      <td>77.167059</td>\n",
       "      <td>...</td>\n",
       "      <td>3.058824</td>\n",
       "      <td>2.352941</td>\n",
       "      <td>15.470588</td>\n",
       "      <td>3.235294</td>\n",
       "      <td>1.352941</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>12.470588</td>\n",
       "      <td>3.529412</td>\n",
       "      <td>2.352941</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.333333</td>\n",
       "      <td>14.067083</td>\n",
       "      <td>4.791667</td>\n",
       "      <td>17.995417</td>\n",
       "      <td>4.981250</td>\n",
       "      <td>27.177917</td>\n",
       "      <td>4.375000</td>\n",
       "      <td>3.938333</td>\n",
       "      <td>4.541667</td>\n",
       "      <td>85.201667</td>\n",
       "      <td>...</td>\n",
       "      <td>2.416667</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>16.708333</td>\n",
       "      <td>5.291667</td>\n",
       "      <td>1.541667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>14.541667</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.359231</td>\n",
       "      <td>14.153846</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>18.897692</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>33.408462</td>\n",
       "      <td>4.807692</td>\n",
       "      <td>4.741538</td>\n",
       "      <td>4.846154</td>\n",
       "      <td>95.214615</td>\n",
       "      <td>...</td>\n",
       "      <td>1.461538</td>\n",
       "      <td>2.230769</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>8.769231</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>10.076923</td>\n",
       "      <td>2.230769</td>\n",
       "      <td>1.076923</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Week2_Quiz1  Week3_MP1  Week3_PR1  Week5_MP2  Week5_PR2  Week7_MP3  \\\n",
       "Grade                                                                       \n",
       "0         0.885208   0.833333   0.208333   0.226458   0.208333   0.000000   \n",
       "2         2.502000  11.800000   5.000000  12.782000   4.986000  14.718000   \n",
       "3         3.872941  13.529412   5.000000  13.888235   4.994118  22.905294   \n",
       "4         3.333333  14.067083   4.791667  17.995417   4.981250  27.177917   \n",
       "5         4.359231  14.153846   5.000000  18.897692   5.000000  33.408462   \n",
       "\n",
       "       Week7_PR3  Week4_Quiz2  Week6_Quiz3  Week8_Total  ...  Week7_Stat2  \\\n",
       "Grade                                                    ...                \n",
       "0       0.000000     0.490625     0.302083     3.154375  ...     1.250000   \n",
       "2       4.000000     4.678000     4.300000    64.766000  ...     1.000000   \n",
       "3       3.970588     4.477059     4.529412    77.167059  ...     3.058824   \n",
       "4       4.375000     3.938333     4.541667    85.201667  ...     2.416667   \n",
       "5       4.807692     4.741538     4.846154    95.214615  ...     1.461538   \n",
       "\n",
       "       Week7_Stat3  Week8_Stat0  Week8_Stat1  Week8_Stat2  Week8_Stat3  \\\n",
       "Grade                                                                    \n",
       "0         0.020833     2.895833     0.291667     1.062500     0.062500   \n",
       "2         2.000000    12.400000     5.000000     0.200000     0.600000   \n",
       "3         2.352941    15.470588     3.235294     1.352941     0.235294   \n",
       "4         2.250000    16.708333     5.291667     1.541667     0.833333   \n",
       "5         2.230769    20.000000     8.769231     0.538462     0.615385   \n",
       "\n",
       "       Week9_Stat0  Week9_Stat1  Week9_Stat2  Week9_Stat3  \n",
       "Grade                                                      \n",
       "0         1.791667     0.000000     0.458333     0.000000  \n",
       "2         8.400000     1.800000     0.600000     0.000000  \n",
       "3        12.470588     3.529412     2.352941     0.000000  \n",
       "4        14.541667     3.083333     1.583333     0.208333  \n",
       "5        10.076923     2.230769     1.076923     0.000000  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check all the column mean of each class\n",
    "data[data.columns[1:48]].groupby(\"Grade\").mean()\n",
    "\n",
    "# although the max value of each week's Stat0 is high, but the mean seems not very high.\n",
    "# column Week8_Total has very high mean value for each class. check the visualization later in the Exploratory data analysis\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DGscWvTstcGm"
   },
   "source": [
    "# Exploratory data analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "F3egqfiCs0bO",
    "outputId": "457435e6-bfa9-4f70-acb6-168355fc6dca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9484f5a0d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD7CAYAAABzGc+QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAOOUlEQVR4nO3dX4yc1XnH8e9TAwJ5EwwFVq6Nuki1UFFQoF4hJKRqF0LkxihwkVRBNDIS0t6kFVVSpU4vqkZqJXNBEgn1olaguKqbBQWQEaA0luNphJQCNn9iiEuhaJsaLFYU22URauXk6cW+bp1lzYxn5w/PzvcjrXbeM+875zm7sz8fn52zE5mJJKmeXxt2AZKk7hjgklSUAS5JRRngklSUAS5JRRngklTUOZ2cFBFzwHvAL4CTmTkZERcDDwETwBzw+5l5rD9lSpKWOpsZ+HRmXpOZk83xdmBfZm4C9jXHkqQBiU428jQz8MnMfOe0tleBqcw8GhHrgVZmXvlRj3PJJZfkxMREV4W+//77rF27tqtrq3LMo8Exr34rHe/BgwffycxLl7Z3tIQCJPDDiEjgbzJzJzCemUcBmhC/rN2DTExMcODAgbOp+/+0Wi2mpqa6urYqxzwaHPPqt9LxRsS/L9ve4Qz8NzLzrSak9wJ/BDyemetOO+dYZl60zLUzwAzA+Pj45tnZ2a4GsLCwwNjYWFfXVuWYR4NjXv1WOt7p6emDpy1f/7/MPKsP4C+APwFeBdY3beuBV9tdu3nz5uzW/v37u762Ksc8Ghzz6rfS8QIHcplMbftLzIhYGxGfOHUb+CzwMvA4sK05bRuwp+t/XiRJZ62TNfBx4LGIOHX+P2TmDyLiOeDhiLgL+Dnwxf6VKUlaqm2AZ+YbwKeXaf9P4KZ+FCVJas+dmJJUlAEuSUUZ4JJUlAEuSUV1uhNz6A69eYI7tz858H7ndmwdeJ+S1Aln4JJUlAEuSUUZ4JJUlAEuSUUZ4JJUlAEuSUUZ4JJUlAEuSUUZ4JJUlAEuSUUZ4JJUlAEuSUUZ4JJUlAEuSUUZ4JJUlAEuSUUZ4JJUlAEuSUUZ4JJUlAEuSUUZ4JJUlAEuSUUZ4JJUlAEuSUUZ4JJUlAEuSUUZ4JJUlAEuSUUZ4JJUVMcBHhFrIuKFiHiiOb4iIp6JiNci4qGIOK9/ZUqSljqbGfjdwOHTju8Bvp2Zm4BjwF29LEyS9NE6CvCI2AhsBb7bHAdwI/D95pRdwG39KFCStLxOZ+DfAb4O/LI5/nXgeGaebI6PABt6XJsk6SOc0+6EiLgFmM/MgxExdap5mVPzDNfPADMA4+PjtFqtrgodvwC+dvXJ9if2WLf19sLCwsJQ+x8GxzwaRm3M/Rpv2wAHbgA+HxGfA84HPsnijHxdRJzTzMI3Am8td3Fm7gR2AkxOTubU1FRXhd63ew/3Huqk3N6au2Nq4H2e0mq16PbrVZVjHg2jNuZ+jbftEkpmfiMzN2bmBPAl4EeZeQewH/hCc9o2YE/Pq5MkndFKXgf+p8BXI+J1FtfE7+9NSZKkTpzVmkRmtoBWc/sN4LrelyRJ6oQ7MSWpKANckooywCWpKANckooywCWpKANckooywCWpKANckooywCWpKANckooywCWpKANckooywCWpKANckooywCWpKANckooywCWpKANckooywCWpKANckooywCWpKANckooywCWpKANckooywCWpKANckooywCWpKANckooywCWpKANckooywCWpKANckooywCWpKANckopqG+ARcX5EPBsRL0XEKxHxzab9ioh4JiJei4iHIuK8/pcrSTqlkxn4fwM3ZuangWuALRFxPXAP8O3M3AQcA+7qX5mSpKXaBnguWmgOz20+ErgR+H7Tvgu4rS8VSpKW1dEaeESsiYgXgXlgL/BvwPHMPNmccgTY0J8SJUnLiczs/OSIdcBjwJ8Df5uZv9W0Xw48lZlXL3PNDDADMD4+vnl2drarQuffPcHbH3R16YpcveHCwXfaWFhYYGxsbGj9D4NjHg2jNuaVjnd6evpgZk4ubT/nbB4kM49HRAu4HlgXEec0s/CNwFtnuGYnsBNgcnIyp6amzrL0Rfft3sO9h86q3J6Yu2Nq4H2e0mq16PbrVZVjHg2jNuZ+jbeTV6Fc2sy8iYgLgM8Ah4H9wBea07YBe3penSTpjDqZ0q4HdkXEGhYD/+HMfCIifgbMRsRfAi8A9/exTknSEm0DPDN/Cly7TPsbwHX9KEqS1J47MSWpKANckooywCWpKANckooywCWpKANckooywCWpKANckooywCWpKANckooywCWpKANckooywCWpKANckooywCWpKANckooywCWpKANckooywCWpKANckooywCWpqLbvSi9JvXbozRPcuf3Jgfc7t2PrwPvsJ2fgklSUAS5JRRngklSUAS5JRRngklSUAS5JRRngklSUAS5JRRngklSUAS5JRRngklSUAS5JRRngklRU2wCPiMsjYn9EHI6IVyLi7qb94ojYGxGvNZ8v6n+5kqRTOpmBnwS+lpm/DVwPfCUirgK2A/sycxOwrzmWJA1I2wDPzKOZ+Xxz+z3gMLABuBXY1Zy2C7itX0VKkj7srNbAI2ICuBZ4BhjPzKOwGPLAZb0uTpJ0ZpGZnZ0YMQb8E/BXmfloRBzPzHWn3X8sMz+0Dh4RM8AMwPj4+ObZ2dmuCp1/9wRvf9DVpSty9YYLB99pY2FhgbGxsaH1PwyOeTSM2s/zSr/H09PTBzNzcml7R2+pFhHnAo8AuzPz0ab57YhYn5lHI2I9ML/ctZm5E9gJMDk5mVNTU93Uz32793DvocG/A9zcHVMD7/OUVqtFt1+vqhzzaBi1n+d+fY87eRVKAPcDhzPzW6fd9Tiwrbm9DdjT8+okSWfUyT+BNwBfBg5FxItN258BO4CHI+Iu4OfAF/tToiRpOW0DPDOfBuIMd9/U23IkSZ1yJ6YkFWWAS1JRBrgkFWWAS1JRBrgkFWWAS1JRBrgkFTX4vaySfsWhN09w5/YnB97v3I6tA+9TveUMXJKKMsAlqSgDXJKKMsAlqSgDXJKKMsAlqSgDXJKKMsAlqSgDXJKKMsAlqSgDXJKKMsAlqSgDXJKKMsAlqSgDXJKKMsAlqSgDXJKK8h15JI2MiSG88xHAg1vW9uVxnYFLUlEGuCQVZYBLUlEGuCQVZYBLUlEGuCQVZYBLUlEGuCQV1TbAI+KBiJiPiJdPa7s4IvZGxGvN54v6W6YkaalOZuAPAluWtG0H9mXmJmBfcyxJGqC2AZ6ZPwbeXdJ8K7Crub0LuK3HdUmS2uh2DXw8M48CNJ8v611JkqRORGa2PyliAngiMz/VHB/PzHWn3X8sM5ddB4+IGWAGYHx8fPPs7GxXhc6/e4K3P+jq0hW5esOFg++0sbCwwNjY2ND6H4ZRHPMoPreHNeZhueLCNSt6Xk9PTx/MzMml7d3+NcK3I2J9Zh6NiPXA/JlOzMydwE6AycnJnJqa6qrD+3bv4d5Dg//jiXN3TA28z1NarRbdfr2qGsUxj+Jze1hjHpYHt6zty/O62yWUx4Ftze1twJ7elCNJ6lQnLyP8HvAT4MqIOBIRdwE7gJsj4jXg5uZYkjRAbf8Pk5m3n+Gum3pciyTpLLgTU5KKMsAlqSgDXJKKMsAlqSgDXJKKMsAlqSgDXJKKMsAlqSgDXJKKMsAlqSgDXJKKMsAlqSgDXJKKMsAlqSgDXJKKMsAlqajReVM6lXDozRPcuf3Jgfc7t2PrwPuUVsoZuCQVZYBLUlEGuCQVZYBLUlEGuCQVZYBLUlEGuCQVZYBLUlEGuCQVZYBLUlEGuCQVZYBLUlEGuCQVZYBLUlEGuCQVZYBLUlEGuCQVtaIAj4gtEfFqRLweEdt7VZQkqb2uAzwi1gB/DfwecBVwe0Rc1avCJEkfbSUz8OuA1zPzjcz8H2AWuLU3ZUmS2llJgG8A/uO04yNNmyRpAFbyrvSxTFt+6KSIGWCmOVyIiFe77O8S4J0ur+1a3DPoHn/FUMY8ZH6fB2QUxzws0/eseLy/uVzjSgL8CHD5accbgbeWnpSZO4GdK+gHgIg4kJmTK32cShzzaHDMq1+/xruSJZTngE0RcUVEnAd8CXi8N2VJktrpegaemScj4g+BfwTWAA9k5is9q0yS9JFWsoRCZj4FPNWjWtpZ8TJMQY55NDjm1a8v443MD/3eUZJUgFvpJamoEgE+alv2I+KBiJiPiJeHXcsgRMTlEbE/Ig5HxCsRcfewa+q3iDg/Ip6NiJeaMX9z2DUNSkSsiYgXIuKJYdcyCBExFxGHIuLFiDjQ08f+uC+hNFv2/xW4mcWXLj4H3J6ZPxtqYX0UEb8LLAB/l5mfGnY9/RYR64H1mfl8RHwCOAjctsq/xwGszcyFiDgXeBq4OzP/ecil9V1EfBWYBD6ZmbcMu55+i4g5YDIze/669woz8JHbsp+ZPwbeHXYdg5KZRzPz+eb2e8BhVvmu3ly00Bye23x8vGdTPRARG4GtwHeHXctqUCHA3bI/QiJiArgWeGa4lfRfs5TwIjAP7M3MVT9m4DvA14FfDruQAUrghxFxsNmZ3jMVAryjLfuqLyLGgEeAP87M/xp2Pf2Wmb/IzGtY3MV8XUSs6uWyiLgFmM/Mg8OuZcBuyMzfYfEvt36lWSLtiQoB3tGWfdXWrAM/AuzOzEeHXc8gZeZxoAVsGXIp/XYD8PlmTXgWuDEi/n64JfVfZr7VfJ4HHmNxWbgnKgS4W/ZXueYXevcDhzPzW8OuZxAi4tKIWNfcvgD4DPAvw62qvzLzG5m5MTMnWPw5/lFm/sGQy+qriFjb/GKeiFgLfBbo2avLPvYBnpkngVNb9g8DD6/2LfsR8T3gJ8CVEXEkIu4adk19dgPwZRZnZC82H58bdlF9th7YHxE/ZXGSsjczR+JldSNmHHg6Il4CngWezMwf9OrBP/YvI5QkLe9jPwOXJC3PAJekogxwSSrKAJekogxwSSrKAJekogxwSSrKAJekov4XRhxql34RwFoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check the distribution of each class\n",
    "data.Grade.hist()\n",
    "\n",
    "# we can also see that the grade 0 class has the most student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "id": "7iAb-rdMxk0V",
    "outputId": "453118bc-c879-4f84-88f4-b40150efda73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f9484fdb9d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "sns.catplot(x=\"Grade\", y = \"Week7_MP3\",kind=\"box\",data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "id": "rVuJ6_fDyrAv",
    "outputId": "d10ec30a-5ac7-4479-a1f2-997a4ff37351"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f9485969cd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(x=\"Grade\", y = \"Week8_Total\",kind=\"box\",data=data)\n",
    "# It seems data is not crossed for \"Week8_Total\" in different classes of \"Grade\".\n",
    "# Maybe \"Week8_Total\" can independently decide the classes of \"Grade\". \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A087O2PDqJ_4",
    "outputId": "b072dd80-de29-4b57-a15b-fb45418356e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     93\n",
      "False    14\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "1     82.43\n",
      "3     80.65\n",
      "5     71.79\n",
      "7     99.71\n",
      "12    96.24\n",
      "13    92.99\n",
      "21    80.04\n",
      "22    81.48\n",
      "30    71.96\n",
      "39    74.04\n",
      "43    92.04\n",
      "48    62.15\n",
      "55    94.27\n",
      "70    82.77\n",
      "Name: Week8_Total, dtype: float64\n",
      "1     82.43\n",
      "3     80.65\n",
      "5     71.79\n",
      "7     99.71\n",
      "12    96.24\n",
      "13    92.99\n",
      "21    80.04\n",
      "22    81.48\n",
      "30    71.96\n",
      "39    74.04\n",
      "43    92.04\n",
      "48    62.15\n",
      "55    94.27\n",
      "70    82.77\n",
      "Name: test, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# check the column Week8_Total\n",
    "\n",
    "# the max values and mean values of Week8_Total are very high, seems column Week8_Total is the sum of some other columns.\n",
    "\n",
    "# try the \"9 grades (Week2_Quiz1, Week3_MP1, ... Week7_MP3)\" first.\n",
    "# add a column of the sum of the 9 grades column\n",
    "data[\"test\"] = data.iloc[:,1:10].sum(axis=1)\n",
    "\n",
    "# check to see if data[\"test\"] is equal to data[\"Week8_Total\"]\n",
    "print ((data['test'] == data[\"Week8_Total\"]).value_counts())\n",
    "print (\"\\n\")\n",
    "# we can see most of 97 values are equal, and only 10 are not equal. \n",
    "# check in more details of the 10 which are not equal.\n",
    "filter = (data['test'] != data[\"Week8_Total\"])\n",
    "\n",
    "print (data[filter].Week8_Total)\n",
    "print (data[filter].test)\n",
    "\n",
    "# they seems also equal.\n",
    "# so the Week8_Total is the sum of \"9 grades (Week2_Quiz1, Week3_MP1, ... Week7_MP3)\".\n",
    "\n",
    "\n",
    "# drop the column \"test\"\n",
    "data.drop(\"test\", axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCa63uFVvaep"
   },
   "source": [
    "# Split data, Train two models, Performance Evaluation, Optimize Random Forest Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "TiJ6oK-ry0Rs"
   },
   "outputs": [],
   "source": [
    "# import split data and Classification performance evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "sl1FBnr0FXav"
   },
   "outputs": [],
   "source": [
    "# Column ID is not needed, \n",
    "# and because the column Week8_Total is the sum of \"9 grades (Week2_Quiz1, Week3_MP1, ... Week7_MP3)\". Maybe column Week8_Total is also not needed. Let's test later.\n",
    "# Crate training and test set, with 20% of the data in the test set.\n",
    "\n",
    "# target/outcome\n",
    "y = data[\"Grade\"]\n",
    "\n",
    "# drop only \"ID\" column for X (predictors). \n",
    "X = data [data.columns[1:47]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# drop \"ID\" and \"Week8_Total\" columns for X (predictors).\n",
    "X_d = data [data.columns[1:47]].drop(\"Week8_Total\", axis=1)\n",
    "X_d_train, X_d_test, y_d_train, y_d_test = train_test_split(X_d, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2w1h8LZMhD9b"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "VH7GvyJmhJVg"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7oTWuCt2kVN0",
    "outputId": "61f298fe-6d32-413a-ab2b-10a8ed867104"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression With Week8_Total:  \n",
      " [[8 2 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 2 0 0]\n",
      " [0 0 2 3 1]\n",
      " [0 0 2 0 1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89        10\n",
      "           2       0.33      1.00      0.50         1\n",
      "           3       0.33      1.00      0.50         2\n",
      "           4       1.00      0.50      0.67         6\n",
      "           5       0.50      0.33      0.40         3\n",
      "\n",
      "    accuracy                           0.68        22\n",
      "   macro avg       0.63      0.73      0.59        22\n",
      "weighted avg       0.84      0.68      0.71        22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inititalize model, random_state to make sure for getting the same result every time,  increase the number of iterations to 10000\n",
    "data_logistic = LogisticRegression( random_state=42, max_iter = 10000)\n",
    "\n",
    "# 1. Try with Week8_Total as predictor. \n",
    "\n",
    "# Fit the training data\n",
    "data_logistic.fit(X_train, y_train)\n",
    "\n",
    "# Look at the model performance \n",
    "pred_logistic = data_logistic.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression With Week8_Total: \", \"\\n\", confusion_matrix(y_test, pred_logistic))\n",
    "\n",
    "print(classification_report(y_test, pred_logistic))\n",
    "\n",
    "# Analyse the result of LogisticRegression with Week8_Total: \n",
    "## From the confusion matrix, we can tell in the test dataset: \n",
    "## 1. There are 10 students who actually get grade 0, the model predict 8 of them correctly to grade 0, and predict wrongly 2 of them to grade 2.\n",
    "## 2. There are 1 students who actually get grade 2, the model predict the 1 correctly to grade 2. \n",
    "## 3. There are 2 students who actually get grade 3, the model predict them all correctly to grade 3.\n",
    "## 4. There are 6 students who actually get grade 4, the model correctly predict 3 of them to grade 4, and the model wrongly predict 2 students to grade 3 and 1 student to grade 5.\n",
    "## 5. There are 3 students who actually get grade 5, the model correctly predict 1 of them to grade 5, and the model wrongly predict 2 students to grade 3.\n",
    "\n",
    "## From the report we can tell: the accuracy of the model is: 0.68.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qHehwptqotnU",
    "outputId": "4c74096d-4940-42b0-d91c-44b892f5d56f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Without Week8_Total:  \n",
      " [[8 2 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 2 0 0]\n",
      " [0 0 2 3 1]\n",
      " [0 0 3 0 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89        10\n",
      "           2       0.33      1.00      0.50         1\n",
      "           3       0.29      1.00      0.44         2\n",
      "           4       1.00      0.50      0.67         6\n",
      "           5       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.64        22\n",
      "   macro avg       0.52      0.66      0.50        22\n",
      "weighted avg       0.77      0.64      0.65        22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Try without Week8_Total as predictor. \n",
    "\n",
    "# Fit the training data\n",
    "data_logistic.fit(X_d_train, y_d_train)\n",
    "\n",
    "# Look at the model performance \n",
    "pred_logistic_d = data_logistic.predict(X_d_test)\n",
    "\n",
    "print(\"Logistic Regression Without Week8_Total: \", \"\\n\", confusion_matrix(y_d_test, pred_logistic_d))\n",
    "\n",
    "print(classification_report(y_d_test, pred_logistic_d))\n",
    "\n",
    "# Analyse the result of LogisticRegression without Week8_Total: \n",
    "## From the confusion matrix, we can tell in the test dataset: \n",
    "## 1. There are 10 students who actually get grade 0, the model predict 8 of them correctly to grade 0, and predict wrongly 2 of them to grade 2.\n",
    "## 2. There are 1 students who actually get grade 2, the model predict the 1 correctly to grade 2. \n",
    "## 3. There are 2 students who actually get grade 3, the model predict them all correctly to grade 3.\n",
    "## 4. There are 6 students who actually get grade 4, the model correctly predict 3 of them to grade 4, and the model wrongly predict 2 students to grade 3 and 1 student to grade 5.\n",
    "## 5. There are 3 students who actually get grade 5, the model predict all 3 students wrongly to grade 3.\n",
    "\n",
    "## From the report we can tell: the accuracy of the model is: 0.64.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAMmIk7w1m-K"
   },
   "source": [
    "According to the test result of LogisticRegression, the model with column Week8_Total as a predictor has better performance, so we should not drop the column Week8_Total in LogisticRegression in order to have a better performance.\n",
    "\n",
    "\n",
    "Next We will find out in the Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jbbr2HQqGvNN"
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "4C6Wm3sGGk-A"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H1Kv9V-8IY47",
    "outputId": "976e5889-8f62-4664-eb15-06c008cd5801"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Week8_Total: \n",
      "[[10  0  0  0  0]\n",
      " [ 0  0  1  0  0]\n",
      " [ 0  0  2  0  0]\n",
      " [ 0  0  1  5  0]\n",
      " [ 0  0  1  2  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.40      1.00      0.57         2\n",
      "           4       0.71      0.83      0.77         6\n",
      "           5       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.77        22\n",
      "   macro avg       0.42      0.57      0.47        22\n",
      "weighted avg       0.69      0.77      0.72        22\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Inititalize model, random_state to make sure for getting the same result every time\n",
    "data_rf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "# 1. Random Forest with Week8_Total.\n",
    "# Fit the training data\n",
    "data_rf.fit(X_train, y_train)\n",
    "\n",
    "# Look at the model performance with the default options\n",
    "pred_rf = data_rf.predict(X_test)\n",
    "\n",
    "print (\"Random Forest with Week8_Total: \")\n",
    "print(confusion_matrix(y_test, pred_rf))\n",
    "\n",
    "print(classification_report(y_test, pred_rf))\n",
    "# Analyse the result\n",
    "\n",
    "## From the confusion matrix, we can tell in the test dataset: \n",
    "## 1. There are 10 students who actually get grade 0, the model predict them all correctly.\n",
    "## 2. There are 1 students who actually get grade 2, the model predict the one wrongly to grade 3.  \n",
    "## 3. There are 2 students who actually get grade 3, the model predict them all correctly.\n",
    "## 4. There are 6 students who actually get grade 4, the model correctly predict 5 of them to get grade 4, and the model predict the other 1 student wrongly to grade 3.\n",
    "## 5. There are 3 students who actually get grade 5, the model predict 2 of them wrongly to get grade 4, and the model predict 1 student to get grade 3.\n",
    "\n",
    "## From the report we can tell: the accuracy of the model is: 0.77. Random Forest is much more better than LogisticRegression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V9QR96cA25bn",
    "outputId": "409f9f53-0506-450e-ec1b-23b60602d6fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest without Week8_Total: \n",
      "[[10  0  0  0  0]\n",
      " [ 0  0  1  0  0]\n",
      " [ 0  0  1  1  0]\n",
      " [ 0  0  1  5  0]\n",
      " [ 1  0  2  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        10\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.20      0.50      0.29         2\n",
      "           4       0.83      0.83      0.83         6\n",
      "           5       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.73        22\n",
      "   macro avg       0.39      0.47      0.41        22\n",
      "weighted avg       0.66      0.73      0.69        22\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. Random Forest without Week8_Total.\n",
    "# Fit the training data\n",
    "data_rf.fit(X_d_train, y_d_train)\n",
    "\n",
    "# Look at the model performance with the default options\n",
    "pred_rf_d = data_rf.predict(X_d_test)\n",
    "\n",
    "print (\"Random Forest without Week8_Total: \")\n",
    "print(confusion_matrix(y_d_test, pred_rf_d))\n",
    "\n",
    "print(classification_report(y_d_test, pred_rf_d))\n",
    "# Analyse the result\n",
    "\n",
    "## From the confusion matrix, we can tell in the test dataset: \n",
    "## 1. There are 10 students who actually get grade 0, the model predict them all correctly.\n",
    "## 2. There are 1 students who actually get grade 2, the model predict the one wrongly to get grade 3.  \n",
    "## 3. There are 2 students who actually get grade 3, the model predict 1 correctly, and the other one wrongly to grade 4.\n",
    "## 4. There are 6 students who actually get grade 4, the model correctly predict 5 of them to get grade 4, and the model predict the other 1 student wrongly to get grade 3.\n",
    "## 5. There are 3 students who actually get grade 5, the model predict 2 of them wrongly to get grade 3, and the model predict 1 student to get grade 0.\n",
    "\n",
    "## From the report we can tell: the accuracy of the model is: 0.73. Random Forest is  better than LogisticRegression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pHEU5eyS4QKv"
   },
   "source": [
    "From the test result of RF, we can also say that, the model with column Week8_Total as predictor has a better performance. We should keep the column Week8_Total. \n",
    "\n",
    "\n",
    "\n",
    "Although Random Forest is much more better than LogisticRegression. We can still try to optimize the Random Forest model to get better performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DkPjs1CaslkH"
   },
   "source": [
    "## Optimizing Random Forest Model by using Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "hJ3F4_fns0Vf"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PM--VhXetQge",
    "outputId": "d35b74c7-0d69-49fa-99d1-b51d46d20168"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best result is 0.8792207792207792 using {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# optimality criterion\n",
    "criterion = ['gini', 'entropy']\n",
    "\n",
    "# Maximum depth of the tree\n",
    "max_depth = [2,4,6,8]\n",
    "\n",
    "# Tree numbers\n",
    "n_estimators = [80,100,200]\n",
    "\n",
    "# define the grid and model \n",
    "grid = dict(criterion = criterion,max_depth=max_depth, n_estimators = n_estimators)\n",
    "\n",
    "data_rf_m = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=data_rf_m, param_grid=grid, scoring='accuracy')\n",
    "\n",
    "grid_result = grid_search.fit(X, y)\n",
    "\n",
    "# Print out the best result\n",
    "print(\"Best result is\", grid_result.best_score_, 'using', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BCH8zHXzwX4Z",
    "outputId": "45fc136f-63f0-4a96-a355-ff374aaefd4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  0  0  0  0]\n",
      " [ 0  0  1  0  0]\n",
      " [ 0  0  2  0  0]\n",
      " [ 0  0  1  5  0]\n",
      " [ 0  0  1  0  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.40      1.00      0.57         2\n",
      "           4       1.00      0.83      0.91         6\n",
      "           5       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.86        22\n",
      "   macro avg       0.68      0.70      0.66        22\n",
      "weighted avg       0.90      0.86      0.86        22\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Check results with optimal parameters\n",
    "data_rf_f = RandomForestClassifier(n_estimators=100, criterion= 'entropy', max_depth=6,random_state = 42)\n",
    "\n",
    "data_rf_f.fit(X_train, y_train)\n",
    "\n",
    "pred_forest = data_rf_f.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred_forest))\n",
    "\n",
    "print(classification_report(y_test, pred_forest))\n",
    "\n",
    "# The accuracy is increased to 0.86, and for grade 5, 2 cases are correctly predicted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVXo9u0jBvnA"
   },
   "source": [
    "# Visualize the confution matrix. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "-RT9kQts59r7",
    "outputId": "13b054f3-cdda-421f-f633-533eb726f848"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9486319090>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## visualize the confution matrix. \n",
    "sns.heatmap(data = confusion_matrix(y_test, pred_forest), cmap = \"Blues\", xticklabels=[0,2,3,4,5],yticklabels=[0,2,3,4,5],annot = True, vmin=0, vmax=7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvERTgaQCPvZ"
   },
   "source": [
    "# Feature Importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Nt9eyfa77Cx",
    "outputId": "b863b4b7-1370-4c22-f3e4-d2d77f4a69dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Week8_Total    0.149734\n",
       "Week7_MP3      0.103042\n",
       "Week5_MP2      0.100283\n",
       "Week3_MP1      0.057930\n",
       "Week5_PR2      0.057121\n",
       "Week3_PR1      0.043617\n",
       "Week5_Stat1    0.042074\n",
       "Week7_PR3      0.035852\n",
       "Week6_Stat1    0.030026\n",
       "Week6_Quiz3    0.029250\n",
       "Week9_Stat0    0.029192\n",
       "Week6_Stat0    0.029111\n",
       "Week7_Stat0    0.026394\n",
       "Week4_Quiz2    0.023989\n",
       "Week8_Stat1    0.019527\n",
       "Week3_Stat0    0.018850\n",
       "Week5_Stat0    0.015687\n",
       "Week2_Quiz1    0.014101\n",
       "Week4_Stat0    0.013417\n",
       "Week1_Stat0    0.012791\n",
       "Week3_Stat3    0.012597\n",
       "Week4_Stat3    0.011534\n",
       "Week4_Stat1    0.011331\n",
       "Week2_Stat1    0.011172\n",
       "Week2_Stat0    0.010905\n",
       "Week3_Stat1    0.010505\n",
       "Week7_Stat1    0.009875\n",
       "Week8_Stat0    0.008529\n",
       "Week2_Stat3    0.007733\n",
       "Week7_Stat3    0.006718\n",
       "Week9_Stat1    0.006438\n",
       "Week6_Stat2    0.004819\n",
       "Week5_Stat2    0.004343\n",
       "Week7_Stat2    0.003907\n",
       "Week9_Stat2    0.003469\n",
       "Week5_Stat3    0.003440\n",
       "Week4_Stat2    0.003286\n",
       "Week1_Stat3    0.003005\n",
       "Week8_Stat3    0.002872\n",
       "Week3_Stat2    0.002820\n",
       "Week1_Stat2    0.002690\n",
       "Week2_Stat2    0.002440\n",
       "Week6_Stat3    0.002099\n",
       "Week8_Stat2    0.001484\n",
       "Week1_Stat1    0.000000\n",
       "Week9_Stat3    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importance\n",
    "pd.Series(data = data_rf_f.feature_importances_, index= X_train.columns).sort_values(ascending=False)\n",
    "\n",
    "## Week8_Total is the most important feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jmoXRmJpzn58"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
